{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 삼각형 이미지 생성 및 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_random_triangle(image_size=(64, 64), line_thickness=2):\n",
    "    image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    points = np.array([\n",
    "        [np.random.randint(0, width//2), np.random.randint(0, height//2)],\n",
    "        [np.random.randint(width//2, width), np.random.randint(height//2, height)],\n",
    "        [np.random.randint(0, width//2), np.random.randint(height//2, height)], \n",
    "        [np.random.randint(width//2, width), np.random.randint(0, height//2)]\n",
    "    ])\n",
    "    \n",
    "    selected_points = points[np.random.choice(points.shape[0], 3, replace=False)]\n",
    "    \n",
    "    cv2.polylines(image, [selected_points], isClosed=True, color=(255, 255, 255), thickness=line_thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사각형 이미지 생성 및 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_random_rectangle(image_size=(64, 64), line_thickness=2):\n",
    "    image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    pt1 = (np.random.randint(0, width), np.random.randint(0, height))\n",
    "    pt2 = (np.random.randint(0, width), np.random.randint(0, height))\n",
    "    \n",
    "    cv2.rectangle(image, pt1, pt2, color=(255, 255, 255), thickness=line_thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원형 이미지 생성 및 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_random_circle(image_size=(64, 64), min_radius=5, max_radius=20, line_thickness=2):\n",
    "    image = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    radius = np.random.randint(min_radius, max_radius)\n",
    "    center_x = np.random.randint(radius, width - radius)\n",
    "    center_y = np.random.randint(radius, height - radius)\n",
    "    center = (center_x, center_y)\n",
    "    \n",
    "    \n",
    "    cv2.circle(image, center, radius, color=(255, 255, 255), thickness=line_thickness)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디렉토리 생성 및 이미지 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been successfully saved.\n"
     ]
    }
   ],
   "source": [
    "triangle_dir = '/home/juneyub12/Desktop/sample/triangle_images'\n",
    "rectangle_dir = '/home/juneyub12/Desktop/sample/rectangle_images'\n",
    "circle_dir = '/home/juneyub12/Desktop/sample/circle_images'\n",
    "\n",
    "os.makedirs(triangle_dir, exist_ok=True)\n",
    "os.makedirs(rectangle_dir, exist_ok=True)\n",
    "os.makedirs(circle_dir, exist_ok=True)\n",
    "\n",
    "# 이미지 생성 및 저장\n",
    "for i in range(1, 1001):\n",
    "    triangle_img = draw_random_triangle()\n",
    "    cv2.imwrite(f'{triangle_dir}/triangle_{i}.png', triangle_img)\n",
    "    \n",
    "    rectangle_img = draw_random_rectangle()\n",
    "    cv2.imwrite(f'{rectangle_dir}/rectangle_{i}.png', rectangle_img)\n",
    "    \n",
    "    circle_img = draw_random_circle()\n",
    "    cv2.imwrite(f'{circle_dir}/circle_{i}.png', circle_img)\n",
    "\n",
    "print(\"Images have been successfully saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class ShapeDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['triangle_images', 'rectangle_images', 'circle_images']\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for idx, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.endswith('.png'):\n",
    "                    self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                    self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로더 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "dataset = ShapeDataset(root_dir='/home/juneyub12/Desktop/sample', transform=transform)\n",
    "\n",
    "# 데이터셋 인덱스 분리\n",
    "indices = list(range(len(dataset)))\n",
    "train_indices, val_indices = train_test_split(indices, test_size=0.2, stratify=dataset.labels)\n",
    "\n",
    "# 학습용 데이터로더\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "train_loader = DataLoader(dataset, batch_size=32, sampler=train_sampler, num_workers=2)\n",
    "\n",
    "# 검증용 데이터로더\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "val_loader = DataLoader(dataset, batch_size=32, sampler=val_sampler, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 32 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.8046\n",
      "Validation Loss: 0.4687, Validation Accuracy: 81.00%\n",
      "Epoch [2/10], Loss: 0.3189\n",
      "Validation Loss: 0.3705, Validation Accuracy: 81.83%\n",
      "Epoch [3/10], Loss: 0.1316\n",
      "Validation Loss: 0.0851, Validation Accuracy: 97.00%\n",
      "Epoch [4/10], Loss: 0.0601\n",
      "Validation Loss: 0.0733, Validation Accuracy: 97.33%\n",
      "Epoch [5/10], Loss: 0.0259\n",
      "Validation Loss: 0.0773, Validation Accuracy: 97.00%\n",
      "Epoch [6/10], Loss: 0.0148\n",
      "Validation Loss: 0.0451, Validation Accuracy: 97.83%\n",
      "Epoch [7/10], Loss: 0.0067\n",
      "Validation Loss: 0.0657, Validation Accuracy: 97.33%\n",
      "Epoch [8/10], Loss: 0.0036\n",
      "Validation Loss: 0.0698, Validation Accuracy: 97.33%\n",
      "Epoch [9/10], Loss: 0.0024\n",
      "Validation Loss: 0.0441, Validation Accuracy: 98.17%\n",
      "Epoch [10/10], Loss: 0.0092\n",
      "Validation Loss: 0.0644, Validation Accuracy: 97.33%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # 검증 루프\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "print('Finished Training')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 600 validation images: 97.33%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the model on the {total} validation images: {100 * correct / total:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
